{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6193268a-7e99-4075-8486-2620d1749c94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sebastian Kuźmiński - sk149029\n",
    "# Problem 1: Generowanie tekstu za pomocą łańcuchów Markowa (wiersz Szymborskiej)\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, sum as spark_sum\n",
    "import random\n",
    "import string\n",
    "spark = SparkSession.builder.appName(\"MarkovChains\").getOrCreate() # inicjalizacja sparka\n",
    "\n",
    "# model Markowa przy użyciu PySpark DataFrame z argumentami tokens (słowa) i order (długość rzędu k=1 lub k=2)\n",
    "def mk_model(tokens, order=1):\n",
    "    ext_tokens = tokens + tokens[:order] # po ostatnim słowie może być pierwszy (cykliczność)\n",
    "    # tworzenie par\n",
    "    pairs = []\n",
    "    for i in range(len(tokens)):\n",
    "        ctx = tuple(ext_tokens[i:i+order]) # ctx = kontekst (słowo)\n",
    "        nxt = ext_tokens[i+order] # nxt = następne słowo\n",
    "        pairs.append(ctx + (nxt,)) # połączenie w parę\n",
    "    \n",
    "    # utworzenie kolumn z parami\n",
    "    schema = [f\"ctx_{i}\" for i in range(order)] + [\"nxt\"]\n",
    "    df = spark.createDataFrame(pairs, schema)\n",
    "    ctx_cols = [f\"ctx_{i}\" for i in range(order)] # grupowanie i obliczanie prawdopodobieństw\n",
    "    \n",
    "    # liczenie wystąpień każdej pary (kontekst, nxt)\n",
    "    counts_df = (\n",
    "        df.groupBy(ctx_cols + [\"nxt\"])\n",
    "        .agg(count(\"*\").alias(\"cnt\"))\n",
    "    )\n",
    "    # liczenie wszystkich wystąpień każdego kontekstu\n",
    "    totals_df = (\n",
    "        counts_df.groupBy(ctx_cols)\n",
    "        .agg(spark_sum(\"cnt\").alias(\"tot\"))\n",
    "    )\n",
    "    # obliczenie prawdopodobieństw\n",
    "    model_df = (\n",
    "        counts_df.join(totals_df, ctx_cols)\n",
    "        .withColumn(\"prob\", col(\"cnt\") / col(\"tot\"))\n",
    "    )\n",
    "    return model_df\n",
    "\n",
    "# generowanie sekwencji używając funkcji mk_model (model_df), start (słowo/słowa startowe), order (rząd k=1 lub k=2), seq_len (ilość wygenerowanych słów).\n",
    "def gen_seq(model_df, start, order, seq_len=500):\n",
    "    if order == 1: # dla k=1\n",
    "        curr = start # słowo start\n",
    "        result = [curr] # lista z wygenerowanymi słowami\n",
    "    else:\n",
    "        curr = start # dla k=2\n",
    "        result = list(curr) # lista z wygenerowanymi słowami, konwertowanie krotki na listę, żeby móc dodawać elementy\n",
    "    \n",
    "    # generowanie kolejnych tokenów\n",
    "    for _ in range(seq_len - order):\n",
    "        # filtrowanie DataFrame po kontekście\n",
    "        if order == 1: # dla k=1\n",
    "            filter_cond = col(\"ctx_0\") == curr # zwrócenie wierszy w kolumnie ctx_0, które mają słowo startowe\n",
    "        else:\n",
    "            filter_cond = None\n",
    "            for i in range(order): # dla k=2, zwrócenie pary słów z kolumn ctx_0 i ctx_1\n",
    "                cond = col(f\"ctx_{i}\") == curr[i]\n",
    "                filter_cond = cond if filter_cond is None else filter_cond & cond\n",
    "        \n",
    "        rows = model_df.filter(filter_cond).collect() # pobranie możliwych następnych słów wraz z szansą\n",
    "        \n",
    "        if not rows: # jeżeli nie znaleziono żadnych możliwych przejść następuje przerwanie\n",
    "            break\n",
    "        \n",
    "        # losowanie i łączenie następnego słowa według prawdopodobieństwa\n",
    "        nexts = [r[\"nxt\"] for r in rows]\n",
    "        probs = [r[\"prob\"] for r in rows]\n",
    "        nxt = random.choices(nexts, weights=probs)[0]\n",
    "        result.append(nxt) # połączenie z następnym słowem\n",
    "        \n",
    "        # aktualizacja kontekstu\n",
    "        if order == 1: # dla k=1 wylosowane wcześniej słowo staje się słowem startowym\n",
    "            curr = nxt\n",
    "        else:\n",
    "            curr = tuple(result[-order:]) # dla k=2 szukamy kolejnej pary słów\n",
    "    return \" \".join(result) # połączenie nowych słów\n",
    "\n",
    "# funkcje statystyczne\n",
    "def avg_len(text): # 1. średnia długość słowa (ilość znaków)\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    return sum(len(t) for t in tokens) / len(tokens)\n",
    "\n",
    "def ttr(text): # 2. różnorodność leksykalna (udział słów występujących tylko raz)\n",
    "    tokens = text.split()\n",
    "    if not tokens:\n",
    "        return 0\n",
    "    return len(set(tokens)) / len(tokens) # set = usuwanie duplikatów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acf0d3f6-7c57-4c65-ba83-bee547c552fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# wiersz \"Dusza się miewa\" Wisławy Szymborskiej\n",
    "raw_text = \"\"\"Duszę się miewa.\n",
    "Nikt nie ma jej bez przerwy i na zawsze.\n",
    "Dzień za dniem, rok za rokiem\n",
    "może bez niej minąć.\n",
    "Czasem tylko w zachwytach\n",
    "i lękach dzieciństwa\n",
    "zagnieżdża się na dłużej.\n",
    "Czasem tylko w zdziwieniu,\n",
    "że jesteśmy starzy.\n",
    "Rzadko nam asystuje\n",
    "podczas zajęć żmudnych,\n",
    "jak przesuwanie mebli,\n",
    "dźwiganie walizek,\n",
    "czy przemierzanie drogi w ciasnych butach.\n",
    "Przy wypełnianiu ankiet\n",
    "i siekaniu mięsa\n",
    "z reguły ma wychodne.\n",
    "Na tysiąc naszych rozmów uczestniczy w jednej\n",
    "a i to niekoniecznie, bo woli milczenie.\n",
    "Kiedy ciało zaczyna nas boleć i boleć,\n",
    "cichcem schodzi z dyżuru.\n",
    "Jest wybredna: niechętnie widzi nas w tłumie,\n",
    "mierzi ją nasza walka o byle przewagę\n",
    "i terkot interesów.\n",
    "Radość i smutek\n",
    "to nie są dla niej dwa różne uczucia.\n",
    "Tylko w ich połączeniu jest przy nas obecna.\n",
    "Możemy na nią liczyć\n",
    "kiedy niczego nie jesteśmy pewni,\n",
    "a wszystkiego ciekawi.\n",
    "Z przedmiotów materialnych\n",
    "lubi zegary z wahadłem\n",
    "i lustra, które pracują gorliwie,\n",
    "nawet gdy nikt nie patrzy.\n",
    "Nie mówi skąd przybywa\n",
    "i kiedy znowu nam zniknie,\n",
    "ale wyraźnie czeka na takie pytania.\n",
    "Wygląda na to,\n",
    "że tak jak ona nam,\n",
    "również i my\n",
    "jesteśmy jej na coś potrzebni.\"\"\"\n",
    "\n",
    "# usunięcie interpunkcji\n",
    "trans = str.maketrans('', '', string.punctuation)\n",
    "clean_text = raw_text.translate(trans)\n",
    "\n",
    "# zamiana na małe litery i podział na tokeny (słowa)\n",
    "tokens = clean_text.lower().split()\n",
    "\n",
    "# tekst źródłowy (wykorzystywany do miar)\n",
    "src_text = \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b48ecec-62fd-4005-9aa5-7dcd487f24ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowo start: 'ona', długość 500 słów\nWylosowana sekwencja:\nona nam asystuje podczas zajęć żmudnych jak przesuwanie mebli dźwiganie walizek czy przemierzanie drogi w zachwytach i smutek to niekoniecznie bo woli milczenie kiedy ciało zaczyna nas boleć i kiedy niczego nie mówi skąd przybywa i my jesteśmy jej na to niekoniecznie bo woli milczenie kiedy niczego nie ma wychodne na to niekoniecznie bo woli milczenie kiedy niczego nie są dla niej dwa różne uczucia tylko w tłumie mierzi ją nasza walka o byle przewagę i kiedy znowu nam również i na takie pytania wygląda na zawsze dzień za dniem rok za dniem rok za rokiem może bez niej dwa różne uczucia tylko w tłumie mierzi ją nasza walka o byle przewagę i lękach dzieciństwa zagnieżdża się miewa nikt nie mówi skąd przybywa i lękach dzieciństwa zagnieżdża się miewa nikt nie ma wychodne na coś potrzebni duszę się miewa nikt nie patrzy nie ma wychodne na takie pytania wygląda na coś potrzebni duszę się na to że tak jak ona nam również i terkot interesów radość i to że tak jak przesuwanie mebli dźwiganie walizek czy przemierzanie drogi w zachwytach i to nie patrzy nie patrzy nie patrzy nie mówi skąd przybywa i my jesteśmy pewni a wszystkiego ciekawi z dyżuru jest wybredna niechętnie widzi nas boleć i lustra które pracują gorliwie nawet gdy nikt nie ma wychodne na tysiąc naszych rozmów uczestniczy w ciasnych butach przy wypełnianiu ankiet i boleć cichcem schodzi z przedmiotów materialnych lubi zegary z dyżuru jest wybredna niechętnie widzi nas obecna możemy na to niekoniecznie bo woli milczenie kiedy ciało zaczyna nas w zdziwieniu że jesteśmy starzy rzadko nam asystuje podczas zajęć żmudnych jak przesuwanie mebli dźwiganie walizek czy przemierzanie drogi w ich połączeniu jest przy nas boleć cichcem schodzi z dyżuru jest wybredna niechętnie widzi nas boleć cichcem schodzi z wahadłem i boleć i my jesteśmy starzy rzadko nam również i lustra które pracują gorliwie nawet gdy nikt nie ma wychodne na dłużej czasem tylko w ciasnych butach przy nas obecna możemy na coś potrzebni duszę się miewa nikt nie patrzy nie jesteśmy jej bez niej dwa różne uczucia tylko w ciasnych butach przy nas obecna możemy na zawsze dzień za dniem rok za rokiem może bez przerwy i my jesteśmy pewni a i to nie mówi skąd przybywa i lękach dzieciństwa zagnieżdża się miewa nikt nie są dla niej dwa różne uczucia tylko w zachwytach i lustra które pracują gorliwie nawet gdy nikt nie mówi skąd przybywa i lękach dzieciństwa zagnieżdża się na takie pytania wygląda na coś potrzebni duszę się miewa nikt nie jesteśmy pewni a wszystkiego ciekawi z wahadłem i smutek to niekoniecznie bo woli milczenie kiedy niczego nie są dla niej minąć czasem tylko w ciasnych butach przy nas boleć cichcem schodzi z dyżuru jest przy nas obecna możemy na takie pytania wygląda na tysiąc naszych rozmów uczestniczy w jednej a wszystkiego ciekawi z wahadłem i boleć cichcem schodzi z dyżuru jest przy wypełnianiu ankiet i to nie są dla niej minąć czasem tylko w zachwytach i na dłużej czasem\n"
     ]
    }
   ],
   "source": [
    "# MODEL K=1\n",
    "order = 1\n",
    "mk1 = mk_model(tokens, order=order)\n",
    "gen1 = []\n",
    "\n",
    "# generowanie sekwencji\n",
    "for i in range(1): #  sekwencja\n",
    "    start_tok = random.choice(tokens) # losowe słowo startowe\n",
    "    seq = gen_seq(mk1, start_tok, order, seq_len=500)\n",
    "    gen1.append(seq)\n",
    "    \n",
    "    print(f\"Słowo start: '{start_tok}', długość {len(seq.split())} słów\")\n",
    "    print(\"Wylosowana sekwencja:\")\n",
    "    print(\" \".join(seq.split()[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124d32a1-1191-411d-a1c1-8c5658bdb7dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Słowa start: ('niej', 'minąć'), długość: 500 słów)\nWylosowana sekwencja:\nniej minąć czasem tylko w ich połączeniu jest przy nas obecna możemy na nią liczyć kiedy niczego nie jesteśmy pewni a wszystkiego ciekawi z przedmiotów materialnych lubi zegary z wahadłem i lustra które pracują gorliwie nawet gdy nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie patrzy nie mówi skąd przybywa i kiedy znowu nam zniknie ale wyraźnie czeka na takie pytania wygląda na to że tak jak ona nam również i my jesteśmy jej na coś potrzebni duszę się miewa nikt nie ma jej bez przerwy i na zawsze dzień za dniem rok za rokiem może bez niej minąć czasem tylko w zdziwieniu że jesteśmy starzy rzadko nam asystuje podczas zajęć żmudnych jak przesuwanie mebli dźwiganie walizek czy przemierzanie drogi w ciasnych butach przy wypełnianiu ankiet i siekaniu mięsa z reguły ma wychodne na tysiąc naszych rozmów uczestniczy w jednej a i to niekoniecznie bo woli milczenie kiedy ciało zaczyna nas boleć i boleć cichcem schodzi z dyżuru jest wybredna niechętnie widzi nas w tłumie mierzi ją nasza walka o byle przewagę i terkot interesów radość i smutek to nie są dla niej dwa różne uczucia tylko w zdziwieniu że jesteśmy starzy rzadko nam asystuje podczas zajęć żmudnych jak przesuwanie mebli dźwiganie walizek czy przemierzanie drogi w ciasnych butach przy wypełnianiu ankiet i siekaniu mięsa z reguły ma wychodne na tysiąc naszych rozmów uczestniczy w jednej a i to niekoniecznie bo woli milczenie kiedy ciało zaczyna nas boleć i boleć cichcem schodzi z dyżuru jest wybredna niechętnie widzi nas w tłumie mierzi ją nasza walka o byle przewagę i terkot interesów radość i smutek to nie są dla niej dwa różne uczucia tylko w ich połączeniu jest przy nas obecna możemy na nią liczyć kiedy niczego nie jesteśmy pewni a wszystkiego ciekawi z przedmiotów materialnych lubi zegary z wahadłem i lustra które pracują gorliwie nawet gdy nikt nie ma jej bez przerwy i na zawsze dzień za dniem rok za rokiem\n"
     ]
    }
   ],
   "source": [
    "# MODEL K=2\n",
    "order = 2\n",
    "mk2 = mk_model(tokens, order=order)\n",
    "gen2 = []\n",
    "\n",
    "# generowanie sekwencji\n",
    "for i in range(1): # jedna sekwencja\n",
    "    idx = random.randint(0, len(tokens) - 2) # losowa para słów jako start\n",
    "    start_pair = (tokens[idx], tokens[idx+1])\n",
    "    seq = gen_seq(mk2, start_pair, order, seq_len=500)\n",
    "    gen2.append(seq)\n",
    "    \n",
    "    print(f\"Słowa start: {start_pair}, długość: {len(seq.split())} słów)\")\n",
    "    print(\"Wylosowana sekwencja:\")\n",
    "    print(\" \".join(seq.split()[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eab58ae-b60b-4cfe-a295-703518018a69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n============================================================\nTABELA PODSUMOWUJĄCA\n============================================================\nModel           Śr. długość słów     Unikalność słów\n------------------------------------------------------------\nŹródło          4.85                 0.7181         \nK=1             4.90                 0.2520         \nKr=2            4.64                 0.2600         \n============================================================\n  - Model K=1 jest bliższy źródłu (dla wylosowanych słów)\n\nType-Token Ratio (Mierzy różnorodność: TTR = unikalne / wszystkie):\n  - Model K=2 jest bliższy TTR źródła (dla wylosowanych słów)\n"
     ]
    }
   ],
   "source": [
    "# miary statystyczne\n",
    "# połączenie sekwencji dla każdego modelu\n",
    "comb1 = \" \".join(gen1)\n",
    "comb2 = \" \".join(gen2)\n",
    "# tabela podsumowująca\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TABELA PODSUMOWUJĄCA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Model':<15} {'Śr. długość słów':<20} {'Unikalność słów':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Źródło':<15} {avg_src:<20.2f} {ttr_src:<15.4f}\")\n",
    "print(f\"{'K=1':<15} {avg_o1:<20.2f} {ttr_o1:<15.4f}\")\n",
    "print(f\"{'Kr=2':<15} {avg_o2:<20.2f} {ttr_o2:<15.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# interpretacja\n",
    "print(f\"  - Model K={1 if abs(avg_o1-avg_src) < abs(avg_o2-avg_src) else 2} jest bliższy źródłu (dla wylosowanych słów)\")\n",
    "\n",
    "print(\"\\nType-Token Ratio (mierzy różnorodność: TTR = unikalne / wszystkie):\")\n",
    "print(f\"  - Model K={1 if abs(ttr_o1-ttr_src) < abs(ttr_o2-ttr_src) else 2} jest bliższy TTR źródła (dla wylosowanych słów)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Praca domowa Markov_2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}